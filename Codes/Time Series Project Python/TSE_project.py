# -*- coding: utf-8 -*-
"""TSE_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WNEG2Wf-GfSnV1eZMUFG9AeY8F92mwjt

# Packages and functions
"""

!pip install quantecon
!pip install YahooFinancials
!pip install arch

import warnings
import pandas as pd
import numpy as np
import statsmodels.api as sm
import statsmodels
import arch
import  matplotlib.pylab as plt

from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
plt.style.use('fivethirtyeight')
from pathlib import Path
from arch.unitroot import ADF, DFGLS, PhillipsPerron, KPSS
from yahoofinancials import YahooFinancials
from datetime import datetime
from statsmodels.tsa.seasonal import seasonal_decompose
from arch.unitroot import ADF
from arch.unitroot import DFGLS
from arch.unitroot import PhillipsPerron
from arch.unitroot import KPSS

def retrieve_stock_data(ticker, start, end):
    json = YahooFinancials(ticker).get_historical_price_data(start, end, 'daily')
    df = pd.DataFrame(columns=['open','close','adjclose'])
    for row in json[ticker]['prices']:
        date = datetime.fromisoformat(row['formatted_date'])
        df.loc[date] = [row['open'], row['close'], row['adjclose']]
    df.index.name = "date"
    return df

"""# Topic introduction

In the global energy landscape, the oil refining sector remains a critical component, influencing not only national economies but also geopolitics and environmental policies. Tüpraş, acronym for Türkiye Petrol Rafinerileri A.Ş., is the largest refining company in Turkey and plays a central role in the country’s energy industry. Founded in 1983 through the privatization of state-owned refineries, Tüpraş has expanded its operations and today operates four refineries in Turkey with significant overall capacity.

This project focuses on the analysis of the historical series of adjusted closing prices of Tüpraş shares from 2022-04-22 to today, with the aim of identifying the best model for predicting future values. Adjusted closing prices are particularly valuable for the analysis as they reflect the real value of the share, adjusted for all effects of dividend distributions and extraordinary transactions, thus providing a more accurate and consistent representation of the company’s historical performance.

# Data Collection
"""

data = retrieve_stock_data("TUPRS.IS", "2022-04-22", "2024-04-22") # Takes data directly from yahooFinance
data = data['adjclose'] # Series of the adjusted closing prices
data

"""# Exploratory Data Analysis"""

# Statistical descriptions
data = data.dropna() # delete "NaN" values
data.describe()

"""The series consists of 497 observations. This number reflects the amount of daily data collected for analysis, indicating a sufficiently long observation period to provide robust statistical results. Prices fluctuated between a minimum of 27.14 and a maximum of 189.90 and the average adjusted closing price of the shares is about 85.01. The standard deviation is 45.60, a relatively high value indicating significant volatility in Tüpraş stock prices over time. This volatility can be influenced by a variety of factors, including changes in the energy sector, oil price fluctuations, and general economic dynamics.  The median is 69.67, which means that half of the prices are below this value and the other half above."""

# Data plot
data.plot(); plt.title("Türkiye Petrol Rafinerileri A.S. Daily");plt.ylabel("Adjusted Closing Prices of TUPRS")
plt.show()

# Hystogram
plt.figure(figsize=(10, 6))
data.hist(bins=30)
plt.title('Histogram of Türkiye Petrol Rafinerileri A.S. Adjusted Closing Prices')
plt.xlabel('TUPRS prices')
plt.ylabel('Frequency')
plt.show()

# Boxplot
plt.figure(figsize=(10, 6))
data.plot(kind='box')
plt.title('Boxplot of TUPRS Adjusted Closing Prices')
plt.ylabel('TUPRS')
plt.show()

# Trend and seasonality components
data.dropna(inplace=True)
decomposition = seasonal_decompose(data, model='additive', period=30)

fig = decomposition.plot()
fig.set_size_inches(12, 8)
fig.suptitle('Decomposition of TUPRS Adjusted Closing Prices')
plt.show()

"""# Stationarity Check"""

# Autocorrelation function
data_acf=plot_acf(data, lags=50); plt.title("Autocorrelation Function of TUPRS")
plt.show()

"""For a stationary series, we expect autocorrelations between series values to quickly decay to zero. This indicates that future values of the series are not significantly dependent on past values.
According to the above, the TUPRS series is not stationary
"""

# Partial autocorrelation function
data_pacf=plot_pacf(data, lags=50); plt.title("Partial Autocorrelation Function of TUPRS")
plt.show()

"""The PACF shows the correlations between the series to a given delay, controlling the effects of all shorter delays, then a quickly decay is expected, for the series to be stationary.
Also for the partial autocorrelation graph, the series seems to be non-stationary.

We can make the first difference of the series and see if the new obtained series is stationary.
"""

# First difference
dif_data = data.diff(1).dropna()
dif_data.plot(); plt.title("First difference Türkiye Petrol Rafinerileri A.S. Adj. Closing Price");
plt.show()
dif_data.dropna()

# Fist difference
# Autocorrelation function
dif_data_acf=plot_acf(dif_data, lags=50); plt.title("Autocorrelation Function of of first difference TUPRS")
plt.show()

# Partial autocorrelation function
dif_pacf=plot_pacf(dif_data, lags=50); plt.title("Partial Autocorrelation Function of first difference TUPRS")
plt.show()

"""In this case, both from the autocorrelation plot and from the partial autocorrelation plot it would seem that the series of the first differences is stationary (the original series would be said difference stationariy).

# Formal Test for Stationarity

However, tests should be used to verify the series stationarity. Following are runned the Augmented Dickey Fuller Test, the KPSS test, the Phillips-Perron test and the DF-GLS test respectively.

Rule of thumb is used to decide whether a series is stationary or not: if the test statistic is less than the critical value, the series is stationary.

## Augmented Dickey Fuller Test
"""

# For TUPRS
adf_data = ADF(data, trend='ct', max_lags=20)  # max_lags since it is not taking into account seriel correlation
adf_data

"""The t-statistic is more than all the critical values: the serie is non-stationary."""

# For First difference of TUPRS
dif_adf_data = ADF(dif_data, trend='ct', max_lags=10)
dif_adf_data

"""The t-statistic is less than all the critical values: the first difference serie is stationary.

## KPSS test
"""

# For TUPRS
kpss_data = KPSS(data, trend='ct')  # KPSS takes into account serial autocorrelation
kpss_data

"""The t-statistic is more than all the critical values: the serie is non-stationary."""

# For First difference of TUPRS
dif_kpss_data=KPSS(dif_data, trend='ct')
dif_kpss_data

"""The t-statistic is less than all the critical values: the first difference serie is stationary.

## Phillips–Perron test
"""

# For TUPRS
PhillipsPerron_data = PhillipsPerron (data, trend='ct')
PhillipsPerron_data

"""The t-statistic is more than all the critical values: the serie is non-stationary."""

# For First difference of TUPRS
dif_PhillipsPerron_data= PhillipsPerron (dif_data, trend='ct')
dif_PhillipsPerron_data

"""The t-statistic is less than all the critical values: the first difference serie is stationary.

## DFGLS (Dickey-Fuller Generalized Least Squares ) Test for TUPRS
"""

# For TUPRS
DFGLS_data = DFGLS(data, trend='ct', max_lags=10)
DFGLS_data

"""The t-statistic is more than all the critical values: the serie is non-stationary."""

# For First difference of TUPRS
dif_DFGLS_data = DFGLS(dif_data, trend='ct', max_lags=10)
dif_DFGLS_data

"""The t-statistic is less than all the critical values: the first difference serie is stationary.

To confirm what was possible to guess from the autocorrelation and partial autocorrelation plots, all tests show that the original series is not stationary while the first difference series is.
The order of integration of the original series is, therefore, 1 (I(1)).

# Data division
"""

train = data[data.index < pd.to_datetime("2024-03-11", format='%Y-%m-%d')]
test = data[data.index > pd.to_datetime("2024-03-11", format='%Y-%m-%d')]

plt.plot(train, color = "black")
plt.plot(test, color = "red")
plt.ylabel('TUPRS Price')
plt.xlabel('Date')
plt.xticks(rotation=45)
plt.title("Train/Test split for TUPRS Data")
plt.show()

y = train

"""Data division is a fundamental part of preparing a time series dataset for predictive modeling, ensuring that the model is trained on past data and tested on future, unseen data to mimic real-world forecasting scenarios.

# Models

Different models will be evaluated in this section: AR(1), AR(2), MA(1), ARIMA(1,1,1), ARIMA(2,1,2) and ARIMA(3,1,2).

For each model a diagnostic test is carried out, the two informative criteria AIC and BIC are highlighted and an in-sample forecast takes place.

To do this we use the SARIMAX function with integration level 1, since we have seen that the series is difference stationary ( first difference series is stationary).

## Model 1
"""

# AR(1) model
mod1=sm.tsa.statespace.SARIMAX(y,trend='c',order=(1,1,0))
results=mod1.fit(disp=False)
print(results.summary())

# Residuals diagnostic
residuals=results.resid
results.plot_diagnostics(figsize=(15,12))

# Information criterias
mod_aic = results.aic
print(mod_aic)
mod_bic = results.bic
print(mod_bic)

# Forecast
y_pred = results.get_forecast(len(test.index))
y_pred_df = y_pred.conf_int(alpha = 0.05)
y_pred_df["Predictions"] = results.predict(start = y_pred_df.index[0], end = y_pred_df.index[-1])
y_pred_df.index = test.index
y_pred_out = y_pred_df["Predictions"]

# Plot combined
plt.plot(train, color = "black")
plt.plot(test, color = "red")
plt.ylabel('TUPRS Price')
plt.xlabel('Date')
plt.xticks(rotation=45)
plt.title("Train/Test split for TUPRS")
plt.plot(y_pred_out, color='green', label = 'Predictions')
plt.legend()
plt.show()


# Forecast performance
mae1=abs(test-y_pred_out).mean()
mape1=100*(abs(test-y_pred_out)/test).mean()
rmse = np.mean((y_pred_out - test)**2)**.5

"""## Model 2"""

# AR(2) model
mod2 = sm.tsa.statespace.SARIMAX(y, order = (2, 1, 0))
results2 = mod2.fit(disp=False)
print(results2.summary())

# Residuals diagnostic
residuals2=results2.resid
results2.plot_diagnostics(figsize=(15,12))

# Information criterias
mod_aic2 = results2.aic
print(mod_aic2)
mod_bic2 = results2.bic
print(mod_bic2)

# Forecast
y_pred2 = results2.get_forecast(len(test.index))
y_pred_df2 = y_pred2.conf_int(alpha = 0.05)
y_pred_df2["Predictions"] = results2.predict(start = y_pred_df2.index[0], end = y_pred_df2.index[-1])
y_pred_df2.index = test.index
y_pred_out2 = y_pred_df2["Predictions"]

# Plot combined
plt.plot(train, color = "black")
plt.plot(test, color = "red")
plt.ylabel('TUPRS Price')
plt.xlabel('Date')
plt.xticks(rotation=45)
plt.title("Train/Test split for TUPRS")
plt.plot(y_pred_out2, color='green', label = 'Predictions')
plt.legend()
plt.show()

# Forecast performance
mae2=abs(test-y_pred_out2).mean()
mape2=100*(abs(test-y_pred_out2)/test).mean()
rmse2 = np.mean((y_pred_out2 - test)**2)**.5

"""## Model 3"""

# MA(1)) model
mod3 = sm.tsa.statespace.SARIMAX(y, order = (0, 1, 1))
results3 = mod3.fit(disp=False)
print(results3.summary())

# Residuals diagnostic
residuals3=results3.resid
results3.plot_diagnostics(figsize=(15,12))

# Information criterias
mod_aic3 = results3.aic
print(mod_aic3)
mod_bic3 = results3.bic
print(mod_bic3)

# Forecast
y_pred3 = results3.get_forecast(len(test.index))
y_pred_df3 = y_pred3.conf_int(alpha = 0.05)
y_pred_df3["Predictions"] = results3.predict(start = y_pred_df3.index[0], end = y_pred_df3.index[-1])
y_pred_df3.index = test.index
y_pred_out3 = y_pred_df3["Predictions"]

# Plot combined
plt.plot(train, color = "black")
plt.plot(test, color = "red")
plt.ylabel('TUPRS Price')
plt.xlabel('Date')
plt.xticks(rotation=45)
plt.title("Train/Test split for TUPRS")
plt.plot(y_pred_out3, color='green', label = 'Predictions')
plt.legend()
plt.show()


# Forecast performance
mae3=abs(test-y_pred_out3).mean()
mape3=100*(abs(test-y_pred_out3)/test).mean()
rmse3 = np.mean((y_pred_out3 - test)**2)**.5

"""## Model 4"""

# ARIMA(1,1,1) model
mod4 = sm.tsa.statespace.SARIMAX(y, order = (1, 1, 1))
results4 = mod4.fit(disp=False)
print(results4.summary())

#Residuals diagnostic
residuals4=results4.resid
results4.plot_diagnostics(figsize=(15,12))

#Information criterias
mod_aic4 = results4.aic
print(mod_aic4)
mod_bic4 = results4.bic
print(mod_bic4)

# Forecast
y_pred4 = results4.get_forecast(len(test.index))
y_pred_df4 = y_pred4.conf_int(alpha = 0.05)
y_pred_df4["Predictions"] = results4.predict(start = y_pred_df4.index[0], end = y_pred_df4.index[-1])
y_pred_df4.index = test.index
y_pred_out4 = y_pred_df4["Predictions"]

# Plot combined
plt.plot(train, color = "black")
plt.plot(test, color = "red")
plt.ylabel('TUPRS Price')
plt.xlabel('Date')
plt.xticks(rotation=45)
plt.title("Train/Test split for TUPRS")
plt.plot(y_pred_out4, color='green', label = 'Predictions')
plt.legend()
plt.show()


# Forecast performance
mae4=abs(test-y_pred_out4).mean()
mape4=100*(abs(test-y_pred_out4)/test).mean()
rmse4 = np.mean((y_pred_out4 - test)**2)**.5

"""## Model 5"""

# ARIMA(2,1,2) model
mod5 = sm.tsa.statespace.SARIMAX(y, order = (2, 1, 2))
results5 = mod5.fit(disp=False)
print(results5.summary())

# Residuals diagnostic
residuals5=results5.resid
results5.plot_diagnostics(figsize=(15,12))

# Information criterias
mod_aic5 = results5.aic
print(mod_aic5)
mod_bic5 = results5.bic
print(mod_bic5)

# Forecast performance
y_pred5 = results5.get_forecast(len(test.index))
y_pred_df5 = y_pred5.conf_int(alpha = 0.05)
y_pred_df5["Predictions"] = results5.predict(start = y_pred_df5.index[0], end = y_pred_df5.index[-1])
y_pred_df5.index = test.index
y_pred_out5 = y_pred_df5["Predictions"]

# Plot combined
plt.plot(train, color = "black")
plt.plot(test, color = "red")
plt.ylabel('TUPRS Price')
plt.xlabel('Date')
plt.xticks(rotation=45)
plt.title("Train/Test split for TUPRS")
plt.plot(y_pred_out5, color='green', label = 'Predictions')
plt.legend()
plt.show()


# Forecast performance
mae5=abs(test-y_pred_out5).mean()
mape5=100*(abs(test-y_pred_out5)/test).mean()
rmse5 = np.mean((y_pred_out5 - test)**2)**.5

"""## Model 6"""

# ARIMA(3,1,2) model
mod6 = sm.tsa.statespace.SARIMAX(y, order = (3, 1, 2))
results6 = mod6.fit(disp=False)
print(results6.summary())

# Residuals diagnostic
residuals6=results6.resid
results6.plot_diagnostics(figsize=(15,12))

# Information criterias
mod_aic6 = results6.aic
print(mod_aic6)
mod_bic6 = results6.bic
print(mod_bic6)

# Forecast
y_pred6 = results6.get_forecast(len(test.index))
y_pred_df6 = y_pred6.conf_int(alpha = 0.05)
y_pred_df6["Predictions"] = results6.predict(start = y_pred_df6.index[0], end = y_pred_df6.index[-1])
y_pred_df6.index = test.index
y_pred_out6 = y_pred_df6["Predictions"]

# Plot combined
plt.plot(train, color = "black")
plt.plot(test, color = "red")
plt.ylabel('TUPRS Price')
plt.xlabel('Date')
plt.xticks(rotation=45)
plt.title("Train/Test split for TUPRS")
plt.plot(y_pred_out6, color='green', label = 'Predictions')
plt.legend()
plt.show()

# Forecast performance
mae6=abs(test-y_pred_out6).mean()
mape6=100*(abs(test-y_pred_out6)/test).mean()
rmse6 = np.mean((y_pred_out6 - test)**2)**.5

"""# Choice of the model

We repeated different estimates for different models, performing a diagnostic of each model and evaluating its predictive capacity for in-saple forecast.

As for the predictive performance of the model, we see that the best model, that is the one that has lower errors, is the first: AR(1).

Specifically the AR(1) model has:

- Mean Absolute Error (MAE) =  7.71

- Mean Absolute Percentage Error (MAPE) = 4.38

- Root Mean Square Error (RMSE) = 10.54
"""

print("Mean Absolute Error")
print(mae1, mae2, mae3, mae4, mae5, mae6)
print("Mean Absolute Percentage Error")
print(mape1, mape2, mape3, mape4, mape5, mape6)
print("Root Mean Square Error")
print(rmse, rmse2, rmse3, rmse4, rmse5, rmse6)

"""# Out-of-Sample Forecast"""

# Real out of sample predictions
tpred_real=results.get_prediction(start=len(data),end=len(data)+len(test),dynamic=True)
pred_ci=tpred_real.conf_int()
pred_real=tpred_real.predicted_mean
pred_real=pred_real.reset_index()
del pred_real['index']
pred_real.columns = ['real predicted']

print(pred_real)